{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a09b04b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from ydata_profiling import ProfileReport\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5fe187f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "date",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "Open",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "High",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Low",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Close",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Adj Close",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Volume",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "headline_concat",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "reddit_concat",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "F_1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "F_2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "F_3",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "F_4",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "F_5",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "F_6",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "F_7",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "target_updown_plus_1_days",
         "rawType": "Int64",
         "type": "integer"
        }
       ],
       "ref": "94f976cb-fcc2-458d-88be-702926c57214",
       "rows": [
        [
         "0",
         "2008-08-08 00:00:00",
         "11432.089844",
         "11759.959961",
         "11388.040039",
         "11734.320312",
         "11734.320312",
         "212830000",
         "b\"Georgia 'downs two Russian warplanes' as countries move to brink of war\". b'BREAKING: Musharraf to be impeached.'. b'Russia Today: Columns of troops roll into South Ossetia; footage from fighting (YouTube)'. b'Russian tanks are moving towards the capital of South Ossetia, which has reportedly been completely destroyed by Georgian artillery fire'. b\"Afghan children raped with 'impunity,' U.N. official says - this is sick, a three year old was raped and they do nothing\". b'150 Russian tanks have entered South Ossetia whilst Georgia shoots down two Russian jets.'. b\"Breaking: Georgia invades South Ossetia, Russia warned it would intervene on SO's side\". b\"The 'enemy combatent' trials are nothing but a sham: Salim Haman has been sentenced to 5 1/2 years, but will be kept longer anyway just because they feel like it.\". b'Georgian troops retreat from S. Osettain capital, presumably leaving several hundred people killed. [VIDEO]'. b'Did the U.S. Prep Georgia for War with Russia?'. b'Rice Gives Green Light for Israel to Attack Iran: Says U.S. has no veto over Israeli military ops'. b'Announcing:Class Action Lawsuit on Behalf of American Public Against the FBI'. b\"So---Russia and Georgia are at war and the NYT's top story is opening ceremonies of the Olympics?  What a fucking disgrace and yet further proof of the decline of journalism.\". b\"China tells Bush to stay out of other countries' affairs\". b'Did World War III start today?'. b'Georgia Invades South Ossetia - if Russia gets involved, will NATO absorb Georgia and unleash a full scale war?'. b'Al-Qaeda Faces Islamist Backlash'. b'Condoleezza Rice: \"The US would not act to prevent an Israeli strike on Iran.\" Israeli Defense Minister Ehud Barak: \"Israel is prepared for uncompromising victory in the case of military hostilities.\"'. b'This is a busy day:  The European Union has approved new sanctions against Iran in protest at its nuclear programme.'. b\"Georgia will withdraw 1,000 soldiers from Iraq to help fight off Russian forces in Georgia's breakaway region of South Ossetia\". b'Why the Pentagon Thinks Attacking Iran is a Bad Idea - US News &amp; World Report'. b'Caucasus in crisis: Georgia invades South Ossetia'. b'Indian shoe manufactory  - And again in a series of \"you do not like your work?\"'. b'Visitors Suffering from Mental Illnesses Banned from Olympics'. b\"No Help for Mexico's Kidnapping Surge\"",
         "b'BREAKING: Musharraf to be impeached.'. b'Russia Today: Columns of troops roll into South Ossetia; footage from fighting (YouTube)'. b'Russian tanks are moving towards the capital of South Ossetia, which has reportedly been completely destroyed by Georgian artillery fire'. b\"Afghan children raped with 'impunity,' U.N. official says - this is sick, a three year old was raped and they do nothing\". b'150 Russian tanks have entered South Ossetia whilst Georgia shoots down two Russian jets.'. b\"Breaking: Georgia invades South Ossetia, Russia warned it would intervene on SO's side\". b\"The 'enemy combatent' trials are nothing but a sham: Salim Haman has been sentenced to 5 1/2 years, but will be kept longer anyway just because they feel like it.\". b'Georgian troops retreat from S. Osettain capital, presumably leaving several hundred people killed. [VIDEO]'. b'Did the U.S. Prep Georgia for War with Russia?'. b'Rice Gives Green Light for Israel to Attack Iran: Says U.S. has no veto over Israeli military ops'. b'Announcing:Class Action Lawsuit on Behalf of American Public Against the FBI'. b'Did World War III start today?'. b\"China tells Bush to stay out of other countries' affairs\". b'Georgia Invades South Ossetia - if Russia gets involved, will NATO absorb Georgia and unleash a full scale war?'. b'Al-Qaeda Faces Islamist Backlash'. b'This is a busy day:  The European Union has approved new sanctions against Iran in protest at its nuclear programme.'. b\"Georgia will withdraw 1,000 soldiers from Iraq to help fight off Russian forces in Georgia's breakaway region of South Ossetia\". b'Why the Pentagon Thinks Attacking Iran is a Bad Idea - US News &amp; World Report'. b'Caucasus in crisis: Georgia invades South Ossetia'. b'Indian shoe manufactory  - And again in a series of \"you do not like your work?\"'. b'Visitors Suffering from Mental Illnesses Banned from Olympics'. b\"No Help for Mexico's Kidnapping Surge\". b\"Georgia 'downs two Russian warplanes' as countries move to brink of war\". b\"So---Russia and Georgia are at war and the NYT's top story is opening ceremonies of the Olympics?  What a fucking disgrace and yet further proof of the decline of journalism.\". b'Condoleezza Rice: \"The US would not act to prevent an Israeli strike on Iran.\" Israeli Defense Minister Ehud Barak: \"Israel is prepared for uncompromising victory in the case of military hostilities.\"'",
         "-0.3065995184836097",
         "0.0073641871002770275",
         "0.0",
         "0.04011084258524516",
         "0.02915364474475101",
         "0.06347583551324211",
         "0.07891243981664507",
         "1"
        ],
        [
         "1",
         "2008-08-11 00:00:00",
         "11729.669922",
         "11867.110352",
         "11675.530273",
         "11782.349609",
         "11782.349609",
         "183190000",
         "b'Why wont America and Nato help us? If they wont help us now, why did we help them in Iraq?'. b'Bush puts foot down on Georgian conflict'. b\"Jewish Georgian minister: Thanks to Israeli training, we're fending off Russia \". b'Georgian army flees in disarray as Russians advance - Gori abandoned to Russia without a shot fired'. b\"Olympic opening ceremony fireworks 'faked'\". b'What were the Mossad with fraudulent New Zealand Passports doing in Iraq?'. b'Russia angered by Israeli military sale to Georgia'. b'An American citizen living in S.Ossetia blames U.S. and Georgian leaders for the genocide of innocent people'. b'Welcome To World War IV! Now In High Definition!'. b\"Georgia's move, a mistake of monumental proportions \". b'Russia presses deeper into Georgia; U.S. says regime change is goal'. b'Abhinav Bindra wins first ever Individual Olympic Gold Medal for India'. b' U.S. ship heads for Arctic to define territory'. b'Drivers in a Jerusalem taxi station threaten to quit rather than work for their new boss - an Arab'. b'The French Team is Stunned by Phelps and the 4x100m Relay Team'. b'Israel and the US behind the Georgian aggression?'. b'\"Do not believe TV, neither Russian nor Georgian. There are much more victims\"'. b'Riots are still going on in Montreal (Canada) because police murdered a boy on Saturday.'. b'China to overtake US as largest manufacturer'. b'War in South Ossetia [PICS]'. b'Israeli Physicians Group Condemns State Torture'. b' Russia has just beaten the United States over the head with Peak Oil'. b'Perhaps *the* question about the Georgia - Russia conflict '. b'Russia is so much better at war'. b\"So this is what it's come to: trading sex for food.\"",
         "b\"So this is what it's come to: trading sex for food.\". b\"Georgia's move, a mistake of monumental proportions \". b'Russia is so much better at war'. b'Perhaps *the* question about the Georgia - Russia conflict '. b'Israeli Physicians Group Condemns State Torture'. b' Russia has just beaten the United States over the head with Peak Oil'. b'Why wont America and Nato help us? If they wont help us now, why did we help them in Iraq?'. b'Bush puts foot down on Georgian conflict'. b\"Jewish Georgian minister: Thanks to Israeli training, we're fending off Russia \". b'Georgian army flees in disarray as Russians advance - Gori abandoned to Russia without a shot fired'. b\"Olympic opening ceremony fireworks 'faked'\". b'What were the Mossad with fraudulent New Zealand Passports doing in Iraq?'. b'Russia angered by Israeli military sale to Georgia'. b'An American citizen living in S.Ossetia blames U.S. and Georgian leaders for the genocide of innocent people'. b'Russia presses deeper into Georgia; U.S. says regime change is goal'. b'Abhinav Bindra wins first ever Individual Olympic Gold Medal for India'. b' U.S. ship heads for Arctic to define territory'. b'Drivers in a Jerusalem taxi station threaten to quit rather than work for their new boss - an Arab'. b'The French Team is Stunned by Phelps and the 4x100m Relay Team'. b'Israel and the US behind the Georgian aggression?'. b'\"Do not believe TV, neither Russian nor Georgian. There are much more victims\"'. b'War in South Ossetia [PICS]'. b'Riots are still going on in Montreal (Canada) because police murdered a boy on Saturday.'. b'Welcome To World War IV! Now In High Definition!'. b'China to overtake US as largest manufacturer'",
         "-0.01495085800808933",
         "0.008142722660244989",
         "113.9247916359611",
         "0.006797250544295029",
         "0.0297274771961871",
         "0.25184943016134087",
         "-0.22669479290968397",
         "0"
        ],
        [
         "2",
         "2008-08-12 00:00:00",
         "11781.700195",
         "11782.349609",
         "11601.519531",
         "11642.469727",
         "11642.469727",
         "173590000",
         "b'Remember that adorable 9-year-old who sang at the opening ceremonies? That was fake, too.'. b\"Russia 'ends Georgia operation'\". b'\"If we had no sexual harassment we would have no children...\"'. b\"Al-Qa'eda is losing support in Iraq because of a brutal crackdown on activities it regards as un-Islamic - including women buying cucumbers\". b'Ceasefire in Georgia: Putin Outmaneuvers the West'. b'Why Microsoft and Intel tried to kill the XO $100 laptop'. b'Stratfor: The Russo-Georgian War and the Balance of Power   '. b\"I'm Trying to Get a Sense of This Whole Georgia-Russia War: Vote Up If You Think Georgia Started It, Or Down If you Think Russia Did\". b\"The US military was surprised by the timing and swiftness of the Russian military's move into South Ossetia and is still trying to sort out what happened, a US defense official said Monday\". b'U.S. Beats War Drum as Iran Dumps the Dollar'. b'Gorbachev: \"Georgian military attacked the South Ossetian capital of Tskhinvali with multiple rocket launchers designed to devastate large areas\"'. b'CNN use footage of Tskhinvali ruins to cover Georgian report [VIDEO]'. b'Beginning a war as the Olympics were opening violates the ancient tradition of a truce to conflict during the Games.  The IOC could respond by taking the 2014 games away from Russia.'. b'55 pyramids as large as the Luxor stacked into a mega-city pyramid in Tokyo Bay'. b'The 11 Top Party Cities in the World'. b'U.S. troops still in Georgia (did you know they were in Georgia in the first place?)'. b'Why Russias response to Georgia was right'. b'Gorbachev accuses U.S. of making a \"serious blunder\" in pursuing its interest in the Caucasus region'. b'Russia, Georgia, and NATO: Cold War Two'. b'Remember that adorable 62-year-old who led your country into war based on evidence? That was fake, too.'. b'War in Georgia: The Israeli connection'. b'All signs point to the US encouraging Georgia to invade South Ossetia. Goddamnit Bush.'. b'Christopher King argues that the US and NATO are behind the Georgian invasion of South Ossetia but have misjudged Russian resolve. '. b'America: The New Mexico?'. b\"BBC NEWS | Asia-Pacific | Extinction 'by man not climate'\"",
         "b\"I'm Trying to Get a Sense of This Whole Georgia-Russia War: Vote Up If You Think Georgia Started It, Or Down If you Think Russia Did\". b'Stratfor: The Russo-Georgian War and the Balance of Power   '. b'Why Microsoft and Intel tried to kill the XO $100 laptop'. b'Ceasefire in Georgia: Putin Outmaneuvers the West'. b'Remember that adorable 9-year-old who sang at the opening ceremonies? That was fake, too.'. b'\"If we had no sexual harassment we would have no children...\"'. b\"Russia 'ends Georgia operation'\". b\"The US military was surprised by the timing and swiftness of the Russian military's move into South Ossetia and is still trying to sort out what happened, a US defense official said Monday\". b\"Al-Qa'eda is losing support in Iraq because of a brutal crackdown on activities it regards as un-Islamic - including women buying cucumbers\". b'U.S. Beats War Drum as Iran Dumps the Dollar'. b'The 11 Top Party Cities in the World'. b'CNN use footage of Tskhinvali ruins to cover Georgian report [VIDEO]'. b'Beginning a war as the Olympics were opening violates the ancient tradition of a truce to conflict during the Games.  The IOC could respond by taking the 2014 games away from Russia.'. b'55 pyramids as large as the Luxor stacked into a mega-city pyramid in Tokyo Bay'. b'U.S. troops still in Georgia (did you know they were in Georgia in the first place?)'. b'Why Russias response to Georgia was right'. b'Gorbachev accuses U.S. of making a \"serious blunder\" in pursuing its interest in the Caucasus region'. b'Russia, Georgia, and NATO: Cold War Two'. b'Remember that adorable 62-year-old who led your country into war based on evidence? That was fake, too.'. b'War in Georgia: The Israeli connection'. b'Christopher King argues that the US and NATO are behind the Georgian invasion of South Ossetia but have misjudged Russian resolve. '. b'America: The New Mexico?'. b\"BBC NEWS | Asia-Pacific | Extinction 'by man not climate'\". b'Gorbachev: \"Georgian military attacked the South Ossetian capital of Tskhinvali with multiple rocket launchers designed to devastate large areas\"'. b'All signs point to the US encouraging Georgia to invade South Ossetia. Goddamnit Bush.'",
         "0.15698941502292663",
         "0.008199205669356615",
         "109.16893536677702",
         "-0.041267464601731",
         "0.015027364271510081",
         "0.19633400241562873",
         "-0.2371751098341172",
         "0"
        ],
        [
         "3",
         "2008-08-13 00:00:00",
         "11632.80957",
         "11633.780273",
         "11453.339844",
         "11532.959961",
         "11532.959961",
         "182550000",
         "b' U.S. refuses Israel weapons to attack Iran: report'. b\"When the president ordered to attack Tskhinvali [the capital of South Ossetia], we knew then we were doomed. How come he didn't realize that?\". b' Israel clears troops who killed Reuters cameraman'. b'Britain\\'s policy of being tough on drugs is \"pointless\", says a former civil servant who once ran the Cabinet\\'s anti-drugs unit.'. b'Body of 14 year old found in trunk; Latest (ransom paid) kidnapping victim in Mexico. Head cop quits, Prez dissolves suspect elite task force'. b'China has moved 10 *million* quake survivors into prefab homes'. b\"Bush announces Operation Get All Up In Russia's Grill. Yeah, this will end well.\". b'Russian forces sink Georgian ships '. b\"The commander of a Navy air reconnaissance squadron that provides the President and the defense secretary the airborne ability to command the nation's nuclear weapons has been relieved of duty\". b\"92% of CNN readers: Russia's actions in Georgia - justified!\". b'USA to send fleet into Black Sea to help Georgia, send troops in \"humanitarian aid exercise\"'. b\"US warns against Israeli plan to strike against Iran's nuclear facilities\". b\"In an intriguing cyberalliance, two Estonian computer experts are heading to Georgia to keep the country's networks running amid an intense military confrontation with Russia\". b'The CNN Effect: Georgia Schools Russia in Information Warfare'. b'Why Russias response to Georgia was right'. b'Elephants extinct by 2020?'. b'US humanitarian missions soon in Georgia - if Russia hits the US - WWIII?'. b\"Georgia's DDOS came from US sources\". b'Russian convoy heads into Georgia, violating truce'. b'Israeli defence minister: US against strike on Iran'. b'Gorbachev: We Had No Choice'. b'Witness: Russian forces head towards Tbilisi in breach of ceasefire agreement'. b' Quarter of Russians blame U.S. for conflict: poll'. b'Georgian president  says US military will take control of seaports and airports - Pentagon denies'. b'2006: Nobel laureate Aleksander Solzhenitsyn accuses U.S., NATO of encircling Russia'",
         "b'Witness: Russian forces head towards Tbilisi in breach of ceasefire agreement'. b\"92% of CNN readers: Russia's actions in Georgia - justified!\". b'Israeli defence minister: US against strike on Iran'. b'Russian convoy heads into Georgia, violating truce'. b\"Georgia's DDOS came from US sources\". b'US humanitarian missions soon in Georgia - if Russia hits the US - WWIII?'. b'Elephants extinct by 2020?'. b'Why Russias response to Georgia was right'. b'The CNN Effect: Georgia Schools Russia in Information Warfare'. b'Gorbachev: We Had No Choice'. b\"In an intriguing cyberalliance, two Estonian computer experts are heading to Georgia to keep the country's networks running amid an intense military confrontation with Russia\". b'Georgian president  says US military will take control of seaports and airports - Pentagon denies'. b\"US warns against Israeli plan to strike against Iran's nuclear facilities\". b' Quarter of Russians blame U.S. for conflict: poll'. b\"The commander of a Navy air reconnaissance squadron that provides the President and the defense secretary the airborne ability to command the nation's nuclear weapons has been relieved of duty\". b'USA to send fleet into Black Sea to help Georgia, send troops in \"humanitarian aid exercise\"'. b' U.S. refuses Israel weapons to attack Iran: report'. b\"When the president ordered to attack Tskhinvali [the capital of South Ossetia], we knew then we were doomed. How come he didn't realize that?\". b' Israel clears troops who killed Reuters cameraman'. b'2006: Nobel laureate Aleksander Solzhenitsyn accuses U.S., NATO of encircling Russia'. b'Body of 14 year old found in trunk; Latest (ransom paid) kidnapping victim in Mexico. Head cop quits, Prez dissolves suspect elite task force'. b'China has moved 10 *million* quake survivors into prefab homes'. b\"Bush announces Operation Get All Up In Russia's Grill. Yeah, this will end well.\". b'Russian forces sink Georgian ships '. b'Britain\\'s policy of being tough on drugs is \"pointless\", says a former civil servant who once ran the Cabinet\\'s anti-drugs unit.'",
         "0.09785730225322148",
         "0.004723797852357839",
         "99.0795033312063",
         "-0.0016927311360601235",
         "-0.010083453473619771",
         "0.17552841821975126",
         "-0.01989263938202738",
         "1"
        ],
        [
         "4",
         "2008-08-14 00:00:00",
         "11532.070312",
         "11718.280273",
         "11450.889648",
         "11615.929688",
         "11615.929688",
         "159790000",
         "b'All the experts admit that we should legalise drugs '. b'War in South Osetia - 89 pictures made by a Russian soldier.'. b'Swedish wrestler Ara Abrahamian throws away medal in Olympic hissy fit '. b'Russia exaggerated the death toll in South Ossetia. Now only 44 were originally killed compared to 2,000.'. b'Missile That Killed 9 Inside Pakistan May Have Been Launched by the CIA'. b\"Rushdie Condemns Random House's Refusal to Publish Novel for Fear of Muslim Retaliation\". b'Poland and US agree to missle defense deal. Interesting timing!'. b'Will the Russians conquer Tblisi? Bet on it, no seriously you can BET on it'. b'Russia exaggerating South Ossetian death toll, says human rights group'. b' Musharraf expected to resign rather than face impeachment'. b'Moscow Made Plans Months Ago to Invade Georgia'. b'Why Russias response to Georgia was right'. b'Nigeria has handed over the potentially oil-rich Bakassi peninsula to Cameroon.'. b'The US and Poland have agreed a preliminary deal on plans for the controversial US defence shield'. b'Russia apparently is sabotaging infrastructure to cripple the already battered Georgian military.'. b'Bank analyst forecast Georgian crisis 2 days early'. b\"Georgia confict could set back Russia's US relations 'for years' | World news | guardian.co.uk\". b'War in the Caucasus is as much the product of an American imperial drive as local conflicts.'. b'\"Non-media\" photos of South Ossetia/Georgia conflict.'. b'Georgian TV reporter shot by Russian sniper during live broadcast [video]'. b'Saudi Arabia: Mother moves to block child marriage'. b'Taliban wages war on humanitarian aid workers'. b'Russia: World  \"can forget about\" Georgia\\'s territorial integrity'. b'Darfur rebels accuse Sudan of mounting major attack'. b'Philippines : Peace Advocate say Muslims need assurance Christians not out to convert them'",
         "b'Taliban wages war on humanitarian aid workers'. b'Saudi Arabia: Mother moves to block child marriage'. b'Georgian TV reporter shot by Russian sniper during live broadcast [video]'. b'\"Non-media\" photos of South Ossetia/Georgia conflict.'. b'War in the Caucasus is as much the product of an American imperial drive as local conflicts.'. b'Bank analyst forecast Georgian crisis 2 days early'. b'Russia apparently is sabotaging infrastructure to cripple the already battered Georgian military.'. b'Nigeria has handed over the potentially oil-rich Bakassi peninsula to Cameroon.'. b'Moscow Made Plans Months Ago to Invade Georgia'. b' Musharraf expected to resign rather than face impeachment'. b'Russia exaggerating South Ossetian death toll, says human rights group'. b'Will the Russians conquer Tblisi? Bet on it, no seriously you can BET on it'. b'Poland and US agree to missle defense deal. Interesting timing!'. b\"Rushdie Condemns Random House's Refusal to Publish Novel for Fear of Muslim Retaliation\". b'Missile That Killed 9 Inside Pakistan May Have Been Launched by the CIA'. b'Russia exaggerated the death toll in South Ossetia. Now only 44 were originally killed compared to 2,000.'. b'Swedish wrestler Ara Abrahamian throws away medal in Olympic hissy fit '. b'War in South Osetia - 89 pictures made by a Russian soldier.'. b'All the experts admit that we should legalise drugs '. b'Why Russias response to Georgia was right'. b'The US and Poland have agreed a preliminary deal on plans for the controversial US defence shield'. b'Philippines : Peace Advocate say Muslims need assurance Christians not out to convert them'. b'Darfur rebels accuse Sudan of mounting major attack'. b'Russia: World  \"can forget about\" Georgia\\'s territorial integrity'. b\"Georgia confict could set back Russia's US relations 'for years' | World news | guardian.co.uk\"",
         "0.2392426162865881",
         "0.006529106925305044",
         "176.78898020627554",
         "-0.05159295694381756",
         "-0.04714500749853931",
         "0.15438185311806207",
         "0.051692343021766986",
         "1"
        ]
       ],
       "shape": {
        "columns": 17,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>headline_concat</th>\n",
       "      <th>reddit_concat</th>\n",
       "      <th>F_1</th>\n",
       "      <th>F_2</th>\n",
       "      <th>F_3</th>\n",
       "      <th>F_4</th>\n",
       "      <th>F_5</th>\n",
       "      <th>F_6</th>\n",
       "      <th>F_7</th>\n",
       "      <th>target_updown_plus_1_days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-08-08</td>\n",
       "      <td>11432.089844</td>\n",
       "      <td>11759.959961</td>\n",
       "      <td>11388.040039</td>\n",
       "      <td>11734.320312</td>\n",
       "      <td>11734.320312</td>\n",
       "      <td>212830000</td>\n",
       "      <td>b\"Georgia 'downs two Russian warplanes' as cou...</td>\n",
       "      <td>b'BREAKING: Musharraf to be impeached.'. b'Rus...</td>\n",
       "      <td>-0.306600</td>\n",
       "      <td>0.007364</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.040111</td>\n",
       "      <td>0.029154</td>\n",
       "      <td>0.063476</td>\n",
       "      <td>0.078912</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-08-11</td>\n",
       "      <td>11729.669922</td>\n",
       "      <td>11867.110352</td>\n",
       "      <td>11675.530273</td>\n",
       "      <td>11782.349609</td>\n",
       "      <td>11782.349609</td>\n",
       "      <td>183190000</td>\n",
       "      <td>b'Why wont America and Nato help us? If they w...</td>\n",
       "      <td>b\"So this is what it's come to: trading sex fo...</td>\n",
       "      <td>-0.014951</td>\n",
       "      <td>0.008143</td>\n",
       "      <td>113.924792</td>\n",
       "      <td>0.006797</td>\n",
       "      <td>0.029727</td>\n",
       "      <td>0.251849</td>\n",
       "      <td>-0.226695</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008-08-12</td>\n",
       "      <td>11781.700195</td>\n",
       "      <td>11782.349609</td>\n",
       "      <td>11601.519531</td>\n",
       "      <td>11642.469727</td>\n",
       "      <td>11642.469727</td>\n",
       "      <td>173590000</td>\n",
       "      <td>b'Remember that adorable 9-year-old who sang a...</td>\n",
       "      <td>b\"I'm Trying to Get a Sense of This Whole Geor...</td>\n",
       "      <td>0.156989</td>\n",
       "      <td>0.008199</td>\n",
       "      <td>109.168935</td>\n",
       "      <td>-0.041267</td>\n",
       "      <td>0.015027</td>\n",
       "      <td>0.196334</td>\n",
       "      <td>-0.237175</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008-08-13</td>\n",
       "      <td>11632.809570</td>\n",
       "      <td>11633.780273</td>\n",
       "      <td>11453.339844</td>\n",
       "      <td>11532.959961</td>\n",
       "      <td>11532.959961</td>\n",
       "      <td>182550000</td>\n",
       "      <td>b' U.S. refuses Israel weapons to attack Iran:...</td>\n",
       "      <td>b'Witness: Russian forces head towards Tbilisi...</td>\n",
       "      <td>0.097857</td>\n",
       "      <td>0.004724</td>\n",
       "      <td>99.079503</td>\n",
       "      <td>-0.001693</td>\n",
       "      <td>-0.010083</td>\n",
       "      <td>0.175528</td>\n",
       "      <td>-0.019893</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008-08-14</td>\n",
       "      <td>11532.070312</td>\n",
       "      <td>11718.280273</td>\n",
       "      <td>11450.889648</td>\n",
       "      <td>11615.929688</td>\n",
       "      <td>11615.929688</td>\n",
       "      <td>159790000</td>\n",
       "      <td>b'All the experts admit that we should legalis...</td>\n",
       "      <td>b'Taliban wages war on humanitarian aid worker...</td>\n",
       "      <td>0.239243</td>\n",
       "      <td>0.006529</td>\n",
       "      <td>176.788980</td>\n",
       "      <td>-0.051593</td>\n",
       "      <td>-0.047145</td>\n",
       "      <td>0.154382</td>\n",
       "      <td>0.051692</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date          Open          High           Low         Close  \\\n",
       "0 2008-08-08  11432.089844  11759.959961  11388.040039  11734.320312   \n",
       "1 2008-08-11  11729.669922  11867.110352  11675.530273  11782.349609   \n",
       "2 2008-08-12  11781.700195  11782.349609  11601.519531  11642.469727   \n",
       "3 2008-08-13  11632.809570  11633.780273  11453.339844  11532.959961   \n",
       "4 2008-08-14  11532.070312  11718.280273  11450.889648  11615.929688   \n",
       "\n",
       "      Adj Close     Volume                                    headline_concat  \\\n",
       "0  11734.320312  212830000  b\"Georgia 'downs two Russian warplanes' as cou...   \n",
       "1  11782.349609  183190000  b'Why wont America and Nato help us? If they w...   \n",
       "2  11642.469727  173590000  b'Remember that adorable 9-year-old who sang a...   \n",
       "3  11532.959961  182550000  b' U.S. refuses Israel weapons to attack Iran:...   \n",
       "4  11615.929688  159790000  b'All the experts admit that we should legalis...   \n",
       "\n",
       "                                       reddit_concat       F_1       F_2  \\\n",
       "0  b'BREAKING: Musharraf to be impeached.'. b'Rus... -0.306600  0.007364   \n",
       "1  b\"So this is what it's come to: trading sex fo... -0.014951  0.008143   \n",
       "2  b\"I'm Trying to Get a Sense of This Whole Geor...  0.156989  0.008199   \n",
       "3  b'Witness: Russian forces head towards Tbilisi...  0.097857  0.004724   \n",
       "4  b'Taliban wages war on humanitarian aid worker...  0.239243  0.006529   \n",
       "\n",
       "          F_3       F_4       F_5       F_6       F_7  \\\n",
       "0    0.000000  0.040111  0.029154  0.063476  0.078912   \n",
       "1  113.924792  0.006797  0.029727  0.251849 -0.226695   \n",
       "2  109.168935 -0.041267  0.015027  0.196334 -0.237175   \n",
       "3   99.079503 -0.001693 -0.010083  0.175528 -0.019893   \n",
       "4  176.788980 -0.051593 -0.047145  0.154382  0.051692   \n",
       "\n",
       "   target_updown_plus_1_days  \n",
       "0                          1  \n",
       "1                          0  \n",
       "2                          0  \n",
       "3                          1  \n",
       "4                          1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet(\"../data/finance_ml_dataset_clean.parquet\", engine = \"fastparquet\")\n",
    "# On supprime la target en valeur\n",
    "df_target = df.copy()\n",
    "df_target = df_target.drop(columns=[\"target_returns_plus_1_days\"])\n",
    "# Vérification\n",
    "df_target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2462eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pré-traitement texte\n",
    "#tfidf_head = TfidfVectorizer(max_features=300)\n",
    "#tfidf_reddit = TfidfVectorizer(max_features=300)\n",
    "#X_head = tfidf_head.fit_transform(df_target[\"headline_concat\"]).toarray()\n",
    "#X_reddit = tfidf_reddit.fit_transform(df_target[\"reddit_concat\"]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7d56f80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Séparation X et Y\n",
    "# On ne prends pas en compte les variables texte\n",
    "\n",
    "# Colonnes numériques\n",
    "num_cols = [\"Low\", \"Close\", \"Adj Close\", \"Volume\", \"F_1\", \"F_2\", \"F_3\", \"F_4\", \"F_5\", \"F_6\", \"F_7\"]\n",
    "\n",
    "# Target\n",
    "y = df[\"target_updown_plus_1_days\"].values  # numpy array\n",
    "\n",
    "X = (df[num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04cca008",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_7\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_7\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">19,456</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ attention_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Attention</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_8 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m11\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_8 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │        \u001b[38;5;34m19,456\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ attention_8 (\u001b[38;5;33mAttention\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │            \u001b[38;5;34m65\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_24 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_25 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,634</span> (84.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m21,634\u001b[0m (84.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,634</span> (84.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m21,634\u001b[0m (84.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Création de séquences temporelles\n",
    "# Les modèles LSTM ont besoin de séquences temporelles en entrée : (batch, time_steps, features)\n",
    "# X normal --> le LSTM ne sait pas que les données sont ordonnées dans le temps.\n",
    "# Permet au LSTM/Attention d’apprendre l’influence du passé sur le futur\n",
    "\n",
    "# sur une fenêtre de 30 jours car : \n",
    "# si trop petit (ex. 5 jours) : le LSTM n’a pas assez de contexte historique\n",
    "# si trop grand (ex. 365 jours) : plus de contexte, mais risque de surcharger le modèle et ralentir l’entraînement\n",
    "# Possible aussi de faire un grid search sur la fenêtre, ou de tester en modifiant\n",
    "def create_sequences(X, y, window=30):\n",
    "    X_seq, y_seq = [], []\n",
    "    for i in range(window, len(X)):\n",
    "        X_seq.append(X[i-window:i])\n",
    "        y_seq.append(y[i])\n",
    "    return np.array(X_seq), np.array(y_seq)\n",
    "\n",
    "X_seq, y_seq = create_sequences(X, y, window=30)\n",
    "# X_seq : vecteurs de features sur plusieurs jours consécutifs (input pour LSTM)\n",
    "# y_seq : target du jour suivant\n",
    "\n",
    "# Définition d'une couche d'attention Keras\n",
    "class Attention(Layer):\n",
    "    def __init__(self):\n",
    "        super(Attention, self).__init__()\n",
    "        self.dense = Dense(1) # couche Dense qui calcule un score d’importance pour chaque timestep\n",
    "\n",
    "    def call(self, inputs, return_attention=False):\n",
    "        score = tf.nn.softmax(self.dense(inputs), \n",
    "                              # softmax : normalise ces scores sur la dimension temporelle : somme = 1 pour chaque séquence\n",
    "                                # Chaque timestep reçoit un poids relatif\n",
    "                              axis=1)  # shape: (batch, time, 1) : score par timestep\n",
    "        context = tf.reduce_sum(score * inputs, axis=1)    # shape: (batch, features)\n",
    "        if return_attention == True:\n",
    "            return context, score # retourne le vecteur de contexte + les poids d’attention\n",
    "        return context # Sinon, retourne juste le vecteur résumé pour le modèle\n",
    "\n",
    "# Définition du modèle avec LSTM + Attention\n",
    "def create_model(n_features):\n",
    "    inputs = Input(shape=(30, # changer en fonction de la fenêtre temporelle\n",
    "                          n_features))\n",
    "    x = LSTM( # LSTM nécessaire pour l'attention car combine les timesteps\n",
    "        64, # taille du vecteur de sortie (plus grand = plus de capacité mais risque d'overfitting)\n",
    "             return_sequences=True # garde la sortie de tous les timesteps\n",
    "             )(inputs)\n",
    "    x = Dropout(0.2)(x) # régularisation pour réduire l'overfitting (plus on augmente, plus ça régularise)\n",
    "    att = Attention()(x)\n",
    "    x = Dense(32, # nombre de neuronnes (plus grand = plus de complexité)\n",
    "              activation=\"selu\")(att) # tester selu, tanh, gelu\n",
    "    output = Dense(1, activation=\"sigmoid\")(x) # sigmoid : permet de retrouver une probabilité entre 0 et 1\n",
    "    model = Model(inputs, output)\n",
    "    model.compile(optimizer=\"adam\", \n",
    "                  loss=\"binary_crossentropy\", # perte adaptée pour classification binaire\n",
    "                  metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "model = create_model(n_features=X_seq.shape[2])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2602b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Epoch 1/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 105ms/step - accuracy: 0.5213 - loss: 0.6928 - val_accuracy: 0.5521 - val_loss: 0.6848\n",
      "Epoch 2/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5701 - loss: 0.6816 - val_accuracy: 0.5613 - val_loss: 0.6800\n",
      "Epoch 3/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5976 - loss: 0.6739 - val_accuracy: 0.5583 - val_loss: 0.6828\n",
      "Epoch 4/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5945 - loss: 0.6748 - val_accuracy: 0.5644 - val_loss: 0.6802\n",
      "Epoch 5/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5701 - loss: 0.6720 - val_accuracy: 0.5399 - val_loss: 0.6861\n",
      "Epoch 6/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5945 - loss: 0.6692 - val_accuracy: 0.5583 - val_loss: 0.6812\n",
      "Epoch 7/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5945 - loss: 0.6671 - val_accuracy: 0.5552 - val_loss: 0.6829\n",
      "Epoch 8/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5976 - loss: 0.6625 - val_accuracy: 0.5521 - val_loss: 0.6968\n",
      "Epoch 9/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6067 - loss: 0.6680 - val_accuracy: 0.5491 - val_loss: 0.6938\n",
      "Epoch 10/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5915 - loss: 0.6683 - val_accuracy: 0.5675 - val_loss: 0.6851\n",
      "Fold 2\n",
      "Epoch 1/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 53ms/step - accuracy: 0.5566 - loss: 0.6887 - val_accuracy: 0.5031 - val_loss: 0.7457\n",
      "Epoch 2/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.5688 - loss: 0.6865 - val_accuracy: 0.4785 - val_loss: 0.7010\n",
      "Epoch 3/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.5703 - loss: 0.6811 - val_accuracy: 0.4785 - val_loss: 0.7033\n",
      "Epoch 4/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.5688 - loss: 0.6800 - val_accuracy: 0.4571 - val_loss: 0.7008\n",
      "Epoch 5/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.5765 - loss: 0.6766 - val_accuracy: 0.4785 - val_loss: 0.7072\n",
      "Epoch 6/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.5765 - loss: 0.6786 - val_accuracy: 0.4847 - val_loss: 0.7146\n",
      "Epoch 7/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.5795 - loss: 0.6735 - val_accuracy: 0.4571 - val_loss: 0.7037\n",
      "Epoch 8/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.5826 - loss: 0.6755 - val_accuracy: 0.4877 - val_loss: 0.7118\n",
      "Epoch 9/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.5841 - loss: 0.6755 - val_accuracy: 0.4847 - val_loss: 0.7174\n",
      "Epoch 10/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.5673 - loss: 0.6760 - val_accuracy: 0.4693 - val_loss: 0.7111\n",
      "Fold 3\n",
      "Epoch 1/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 0.5204 - loss: 0.6945 - val_accuracy: 0.4417 - val_loss: 0.7491\n",
      "Epoch 2/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.5357 - loss: 0.6922 - val_accuracy: 0.4417 - val_loss: 0.7335\n",
      "Epoch 3/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.5469 - loss: 0.6876 - val_accuracy: 0.4816 - val_loss: 0.7031\n",
      "Epoch 4/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.5449 - loss: 0.6860 - val_accuracy: 0.4693 - val_loss: 0.7137\n",
      "Epoch 5/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.5602 - loss: 0.6843 - val_accuracy: 0.4417 - val_loss: 0.7727\n",
      "Epoch 6/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5357 - loss: 0.6838 - val_accuracy: 0.4785 - val_loss: 0.7100\n",
      "Epoch 7/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.5500 - loss: 0.6832 - val_accuracy: 0.4417 - val_loss: 0.7252\n",
      "Epoch 8/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5633 - loss: 0.6848 - val_accuracy: 0.4387 - val_loss: 0.7359\n",
      "Epoch 9/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.5633 - loss: 0.6824 - val_accuracy: 0.4785 - val_loss: 0.7083\n",
      "Epoch 10/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5684 - loss: 0.6818 - val_accuracy: 0.4417 - val_loss: 0.7404\n",
      "Fold 4\n",
      "Epoch 1/10\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 36ms/step - accuracy: 0.5023 - loss: 0.7037 - val_accuracy: 0.5460 - val_loss: 0.6886\n",
      "Epoch 2/10\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5329 - loss: 0.6891 - val_accuracy: 0.5399 - val_loss: 0.6887\n",
      "Epoch 3/10\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5306 - loss: 0.6879 - val_accuracy: 0.5460 - val_loss: 0.6873\n",
      "Epoch 4/10\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.5444 - loss: 0.6864 - val_accuracy: 0.5460 - val_loss: 0.6863\n",
      "Epoch 5/10\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.5536 - loss: 0.6867 - val_accuracy: 0.5460 - val_loss: 0.6881\n",
      "Epoch 6/10\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.5567 - loss: 0.6857 - val_accuracy: 0.5460 - val_loss: 0.6912\n",
      "Epoch 7/10\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5406 - loss: 0.6848 - val_accuracy: 0.5460 - val_loss: 0.6851\n",
      "Epoch 8/10\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5467 - loss: 0.6842 - val_accuracy: 0.5429 - val_loss: 0.6894\n",
      "Epoch 9/10\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5528 - loss: 0.6847 - val_accuracy: 0.5460 - val_loss: 0.6940\n",
      "Epoch 10/10\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.5551 - loss: 0.6835 - val_accuracy: 0.5460 - val_loss: 0.7005\n",
      "Fold 5\n",
      "Epoch 1/10\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 30ms/step - accuracy: 0.5312 - loss: 0.6985 - val_accuracy: 0.5123 - val_loss: 0.7077\n",
      "Epoch 2/10\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.5398 - loss: 0.6888 - val_accuracy: 0.5000 - val_loss: 0.6986\n",
      "Epoch 3/10\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.5441 - loss: 0.6869 - val_accuracy: 0.5000 - val_loss: 0.7007\n",
      "Epoch 4/10\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.5502 - loss: 0.6894 - val_accuracy: 0.4939 - val_loss: 0.7032\n",
      "Epoch 5/10\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.5600 - loss: 0.6844 - val_accuracy: 0.5000 - val_loss: 0.7027\n",
      "Epoch 6/10\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.5484 - loss: 0.6860 - val_accuracy: 0.5000 - val_loss: 0.7044\n",
      "Epoch 7/10\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.5570 - loss: 0.6849 - val_accuracy: 0.4969 - val_loss: 0.7177\n",
      "Epoch 8/10\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.5705 - loss: 0.6825 - val_accuracy: 0.5061 - val_loss: 0.7085\n",
      "Epoch 9/10\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.5588 - loss: 0.6847 - val_accuracy: 0.5061 - val_loss: 0.7139\n",
      "Epoch 10/10\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.5729 - loss: 0.6799 - val_accuracy: 0.5092 - val_loss: 0.7121\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step\n"
     ]
    }
   ],
   "source": [
    "# Entraînement\n",
    "tscv = TimeSeriesSplit(n_splits=5) \n",
    "# les données sont découpées en K=5 expériences successives\n",
    "# Chaque split utilise les données antérieures pour entraîner et les données postérieures pour tester\n",
    "# à chaque fold le train s'aggrandit\n",
    "# pratique standard : performance finale = moyenne ± écart-type sur les folds\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(tscv.split(X_seq)):\n",
    "    print(f\"Fold {fold+1}\")\n",
    "\n",
    "    X_train, X_test = X_seq[train_idx], X_seq[test_idx]\n",
    "    y_train, y_test = y_seq[train_idx], y_seq[test_idx]\n",
    "\n",
    "    # Reshape pour le scaling : (batch*time, features)\n",
    "    n_timesteps = X_train.shape[1]\n",
    "    n_features = X_train.shape[2]\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    X_train_2d = X_train.reshape(-1, n_features)\n",
    "    X_test_2d = X_test.reshape(-1, n_features)\n",
    "\n",
    "    X_train_scaled = scaler.fit_transform(X_train_2d)\n",
    "    X_test_scaled = scaler.transform(X_test_2d)\n",
    "\n",
    "    # Retour en 3D\n",
    "    X_train_scaled = X_train_scaled.reshape(-1, n_timesteps, n_features)\n",
    "    X_test_scaled = X_test_scaled.reshape(-1, n_timesteps, n_features)\n",
    "\n",
    "    model = create_model(n_features=n_features)\n",
    "\n",
    "    model.fit(\n",
    "        X_train_scaled, y_train,\n",
    "        validation_data=(X_test_scaled, y_test),\n",
    "        epochs=10,\n",
    "        batch_size=32,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "# Prédiction sur le dernier fold\n",
    "y_pred = (model.predict(X_test_scaled) > 0.5).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a6ebad70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.50920245398773\n",
      "Confusion Matrix:\n",
      " [[ 46 113]\n",
      " [ 47 120]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.29      0.37       159\n",
      "           1       0.52      0.72      0.60       167\n",
      "\n",
      "    accuracy                           0.51       326\n",
      "   macro avg       0.50      0.50      0.48       326\n",
      "weighted avg       0.51      0.51      0.49       326\n",
      "\n",
      "ROC-AUC: 0.503935525176063\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score\n",
    "\n",
    "# Accuracy\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", acc)\n",
    "# Matrice de confusion\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "# Rapport complet\n",
    "print(classification_report(y_test, y_pred))\n",
    "# ROC-AUC\n",
    "roc = roc_auc_score(y_test, y_pred)\n",
    "print(\"ROC-AUC:\", roc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c214ccde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Epoch 1/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 92ms/step - accuracy: 0.5000 - loss: 0.6977 - val_accuracy: 0.5736 - val_loss: 0.6866\n",
      "Epoch 2/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5549 - loss: 0.6827 - val_accuracy: 0.5521 - val_loss: 0.6836\n",
      "Epoch 3/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5823 - loss: 0.6781 - val_accuracy: 0.5767 - val_loss: 0.6854\n",
      "Epoch 4/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5701 - loss: 0.6789 - val_accuracy: 0.5706 - val_loss: 0.6870\n",
      "Epoch 5/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5732 - loss: 0.6744 - val_accuracy: 0.5491 - val_loss: 0.6942\n",
      "Epoch 6/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5945 - loss: 0.6748 - val_accuracy: 0.5706 - val_loss: 0.6865\n",
      "Epoch 7/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5915 - loss: 0.6731 - val_accuracy: 0.5736 - val_loss: 0.6865\n",
      "Epoch 8/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5823 - loss: 0.6686 - val_accuracy: 0.5675 - val_loss: 0.6834\n",
      "Epoch 9/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5884 - loss: 0.6668 - val_accuracy: 0.5583 - val_loss: 0.6831\n",
      "Epoch 10/10\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5915 - loss: 0.6647 - val_accuracy: 0.5675 - val_loss: 0.6822\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step\n",
      "Accuracy Fold 1: 0.5675\n",
      "ROC-AUC Fold 1: 0.5233\n",
      "Confusion Matrix:\n",
      " [[ 31 108]\n",
      " [ 33 154]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.22      0.31       139\n",
      "           1       0.59      0.82      0.69       187\n",
      "\n",
      "    accuracy                           0.57       326\n",
      "   macro avg       0.54      0.52      0.50       326\n",
      "weighted avg       0.54      0.57      0.52       326\n",
      "\n",
      "Fold 2\n",
      "Epoch 1/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 53ms/step - accuracy: 0.5765 - loss: 0.6861 - val_accuracy: 0.4755 - val_loss: 0.7009\n",
      "Epoch 2/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.5719 - loss: 0.6799 - val_accuracy: 0.4908 - val_loss: 0.7101\n",
      "Epoch 3/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.5780 - loss: 0.6793 - val_accuracy: 0.4632 - val_loss: 0.7025\n",
      "Epoch 4/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.5535 - loss: 0.6817 - val_accuracy: 0.5153 - val_loss: 0.6991\n",
      "Epoch 5/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.5841 - loss: 0.6788 - val_accuracy: 0.4877 - val_loss: 0.7036\n",
      "Epoch 6/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.5826 - loss: 0.6756 - val_accuracy: 0.4939 - val_loss: 0.7044\n",
      "Epoch 7/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.5826 - loss: 0.6760 - val_accuracy: 0.4816 - val_loss: 0.7096\n",
      "Epoch 8/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.5749 - loss: 0.6750 - val_accuracy: 0.4816 - val_loss: 0.7116\n",
      "Epoch 9/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.5795 - loss: 0.6726 - val_accuracy: 0.5153 - val_loss: 0.7106\n",
      "Epoch 10/10\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.5780 - loss: 0.6757 - val_accuracy: 0.4877 - val_loss: 0.7065\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step\n",
      "Accuracy Fold 2: 0.4877\n",
      "ROC-AUC Fold 2: 0.4840\n",
      "Confusion Matrix:\n",
      " [[ 29 132]\n",
      " [ 35 130]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.18      0.26       161\n",
      "           1       0.50      0.79      0.61       165\n",
      "\n",
      "    accuracy                           0.49       326\n",
      "   macro avg       0.47      0.48      0.43       326\n",
      "weighted avg       0.47      0.49      0.44       326\n",
      "\n",
      "Fold 3\n",
      "Epoch 1/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - accuracy: 0.5316 - loss: 0.6963 - val_accuracy: 0.4417 - val_loss: 0.7321\n",
      "Epoch 2/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.5388 - loss: 0.6926 - val_accuracy: 0.4325 - val_loss: 0.7212\n",
      "Epoch 3/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.5480 - loss: 0.6856 - val_accuracy: 0.4785 - val_loss: 0.7122\n",
      "Epoch 4/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.5622 - loss: 0.6877 - val_accuracy: 0.4969 - val_loss: 0.6994\n",
      "Epoch 5/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.5622 - loss: 0.6832 - val_accuracy: 0.4325 - val_loss: 0.7349\n",
      "Epoch 6/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.5571 - loss: 0.6848 - val_accuracy: 0.4417 - val_loss: 0.7791\n",
      "Epoch 7/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.5398 - loss: 0.6846 - val_accuracy: 0.4417 - val_loss: 0.7576\n",
      "Epoch 8/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.5643 - loss: 0.6830 - val_accuracy: 0.4417 - val_loss: 0.7860\n",
      "Epoch 9/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.5571 - loss: 0.6833 - val_accuracy: 0.4417 - val_loss: 0.7521\n",
      "Epoch 10/10\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.5643 - loss: 0.6819 - val_accuracy: 0.4601 - val_loss: 0.7343\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step\n",
      "Accuracy Fold 3: 0.4601\n",
      "ROC-AUC Fold 3: 0.4976\n",
      "Confusion Matrix:\n",
      " [[118  26]\n",
      " [150  32]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.82      0.57       144\n",
      "           1       0.55      0.18      0.27       182\n",
      "\n",
      "    accuracy                           0.46       326\n",
      "   macro avg       0.50      0.50      0.42       326\n",
      "weighted avg       0.50      0.46      0.40       326\n",
      "\n",
      "Fold 4\n",
      "Epoch 1/10\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 35ms/step - accuracy: 0.5276 - loss: 0.6937 - val_accuracy: 0.5859 - val_loss: 0.6890\n",
      "Epoch 2/10\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.5345 - loss: 0.6889 - val_accuracy: 0.5061 - val_loss: 0.6919\n",
      "Epoch 3/10\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.5452 - loss: 0.6897 - val_accuracy: 0.5521 - val_loss: 0.6859\n",
      "Epoch 4/10\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.5490 - loss: 0.6873 - val_accuracy: 0.5460 - val_loss: 0.6868\n",
      "Epoch 5/10\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.5536 - loss: 0.6873 - val_accuracy: 0.5460 - val_loss: 0.6941\n",
      "Epoch 6/10\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.5590 - loss: 0.6845 - val_accuracy: 0.5460 - val_loss: 0.6938\n",
      "Epoch 7/10\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.5582 - loss: 0.6842 - val_accuracy: 0.5675 - val_loss: 0.6842\n",
      "Epoch 8/10\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.5521 - loss: 0.6849 - val_accuracy: 0.5521 - val_loss: 0.6883\n",
      "Epoch 9/10\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.5406 - loss: 0.6854 - val_accuracy: 0.5552 - val_loss: 0.6849\n",
      "Epoch 10/10\n",
      "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.5666 - loss: 0.6826 - val_accuracy: 0.5460 - val_loss: 0.6974\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step\n",
      "Accuracy Fold 4: 0.5460\n",
      "ROC-AUC Fold 4: 0.5000\n",
      "Confusion Matrix:\n",
      " [[  0 148]\n",
      " [  0 178]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       148\n",
      "           1       0.55      1.00      0.71       178\n",
      "\n",
      "    accuracy                           0.55       326\n",
      "   macro avg       0.27      0.50      0.35       326\n",
      "weighted avg       0.30      0.55      0.39       326\n",
      "\n",
      "Fold 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\isali\\Documents\\cours\\M2_ECAP\\Deep Learning\\projet_deep_learning\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\isali\\Documents\\cours\\M2_ECAP\\Deep Learning\\projet_deep_learning\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\isali\\Documents\\cours\\M2_ECAP\\Deep Learning\\projet_deep_learning\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\isali\\Documents\\cours\\M2_ECAP\\Deep Learning\\projet_deep_learning\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - accuracy: 0.5270 - loss: 0.6931 - val_accuracy: 0.5123 - val_loss: 0.6996\n",
      "Epoch 2/10\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5429 - loss: 0.6905 - val_accuracy: 0.4877 - val_loss: 0.6979\n",
      "Epoch 3/10\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5398 - loss: 0.6876 - val_accuracy: 0.4969 - val_loss: 0.6940\n",
      "Epoch 4/10\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5404 - loss: 0.6876 - val_accuracy: 0.5092 - val_loss: 0.6962\n",
      "Epoch 5/10\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.5564 - loss: 0.6850 - val_accuracy: 0.4939 - val_loss: 0.7003\n",
      "Epoch 6/10\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5490 - loss: 0.6855 - val_accuracy: 0.4939 - val_loss: 0.6986\n",
      "Epoch 7/10\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5594 - loss: 0.6853 - val_accuracy: 0.4969 - val_loss: 0.7049\n",
      "Epoch 8/10\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5662 - loss: 0.6843 - val_accuracy: 0.4908 - val_loss: 0.7013\n",
      "Epoch 9/10\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5625 - loss: 0.6830 - val_accuracy: 0.4908 - val_loss: 0.7260\n",
      "Epoch 10/10\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.5692 - loss: 0.6831 - val_accuracy: 0.4969 - val_loss: 0.7054\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step\n",
      "Accuracy Fold 5: 0.4969\n",
      "ROC-AUC Fold 5: 0.4932\n",
      "Confusion Matrix:\n",
      " [[ 54 105]\n",
      " [ 59 108]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.34      0.40       159\n",
      "           1       0.51      0.65      0.57       167\n",
      "\n",
      "    accuracy                           0.50       326\n",
      "   macro avg       0.49      0.49      0.48       326\n",
      "weighted avg       0.49      0.50      0.48       326\n",
      "\n",
      "Performance globale :\n",
      "Accuracy moyenne: 0.5117 ± 0.0393\n",
      "Precision moyenne: 0.4544 ± 0.1576\n",
      "Recall moyen: 0.4996 ± 0.3348\n",
      "F1-score moyen: 0.4369 ± 0.2170\n",
      "ROC-AUC moyen: 0.4996 ± 0.0130\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Nombre de folds\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# Listes pour stocker les métriques par fold\n",
    "acc_list = []\n",
    "roc_list = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "f1_list = []\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(tscv.split(X_seq)):\n",
    "    print(f\"Fold {fold + 1}\")\n",
    "\n",
    "    # Split temporel\n",
    "    X_train, X_test = X_seq[train_idx], X_seq[test_idx]\n",
    "    y_train, y_test = y_seq[train_idx], y_seq[test_idx]\n",
    "\n",
    "    n_timesteps = X_train.shape[1]\n",
    "    n_features = X_train.shape[2]\n",
    "\n",
    "    # Scaling\n",
    "    scaler = StandardScaler()\n",
    "    X_train_2d = X_train.reshape(-1, n_features)\n",
    "    X_test_2d = X_test.reshape(-1, n_features)\n",
    "    X_train_scaled = scaler.fit_transform(X_train_2d)\n",
    "    X_test_scaled = scaler.transform(X_test_2d)\n",
    "    X_train_scaled = X_train_scaled.reshape(-1, n_timesteps, n_features)\n",
    "    X_test_scaled = X_test_scaled.reshape(-1, n_timesteps, n_features)\n",
    "\n",
    "    # Création d'un modèle par fold\n",
    "    model = create_model(n_features=n_features)\n",
    "\n",
    "    # Entraînement\n",
    "    model.fit(\n",
    "        X_train_scaled, y_train,\n",
    "        validation_data=(X_test_scaled, y_test),\n",
    "        epochs=10, # le modèle passe 10 fois sur toutes les données d'entrainement pour chaque fold\n",
    "        batch_size=32,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Prédiction sur le test\n",
    "    y_pred = (model.predict(X_test_scaled) > 0.5).astype(int)\n",
    "\n",
    "    # Calcul des métriques\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    roc = roc_auc_score(y_test, y_pred)\n",
    "    acc_list.append(acc)\n",
    "    roc_list.append(roc)\n",
    "    precision_list.append(precision_score(y_test, y_pred, average=None))\n",
    "    recall_list.append(recall_score(y_test, y_pred, average=None))\n",
    "    f1_list.append(f1_score(y_test, y_pred, average=None))\n",
    "\n",
    "    print(f\"Accuracy Fold {fold+1}: {acc:.4f}\")\n",
    "    print(f\"ROC-AUC Fold {fold+1}: {roc:.4f}\")\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Moyenne et écart-type des métriques\n",
    "print(\"Performance globale :\")\n",
    "print(f\"Accuracy moyenne: {np.mean(acc_list):.4f} ± {np.std(acc_list):.4f}\")\n",
    "print(f\"Precision moyenne: {np.mean(precision_list):.4f} ± {np.std(precision_list):.4f}\")\n",
    "print(f\"Recall moyen: {np.mean(recall_list):.4f} ± {np.std(recall_list):.4f}\")\n",
    "print(f\"F1-score moyen: {np.mean(f1_list):.4f} ± {np.std(f1_list):.4f}\")\n",
    "print(f\"ROC-AUC moyen: {np.mean(roc_list):.4f} ± {np.std(roc_list):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d51d60d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fenêtre temporelle = 10 ===\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step\n",
      "Accuracy moyenne: 0.5046\n",
      "\n",
      "=== Fenêtre temporelle = 20 ===\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step\n",
      "Accuracy moyenne: 0.4915\n",
      "\n",
      "=== Fenêtre temporelle = 30 ===\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step\n",
      "Accuracy moyenne: 0.4988\n",
      "\n",
      "=== Fenêtre temporelle = 50 ===\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step\n",
      "Accuracy moyenne: 0.5028\n",
      "\n",
      "=== Fenêtre temporelle = 60 ===\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step\n",
      "Accuracy moyenne: 0.4966\n",
      "\n",
      "Fenêtre optimale: 10 avec accuracy = 0.5045592705167173\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dropout, Dense, Layer\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# --- Création de séquences temporelles ---\n",
    "# Les modèles LSTM ont besoin de séquences temporelles en entrée : (batch, time_steps, features)\n",
    "# X normal --> le LSTM ne sait pas que les données sont ordonnées dans le temps.\n",
    "# Permet au LSTM/Attention d’apprendre l’influence du passé sur le futur\n",
    "# On peut tester différentes tailles de fenêtre pour trouver le meilleur compromis\n",
    "def create_sequences(X, y, window):\n",
    "    X_seq, y_seq = [], []\n",
    "    for i in range(window, len(X)):\n",
    "        X_seq.append(X[i-window:i])  # vecteurs de features sur plusieurs jours consécutifs\n",
    "        y_seq.append(y[i])           # target du jour suivant\n",
    "    return np.array(X_seq), np.array(y_seq)\n",
    "\n",
    "# --- Définition d'une couche d'attention personnalisée ---\n",
    "# Chaque timestep reçoit un poids relatif selon son importance pour la prédiction\n",
    "# La couche renvoie un vecteur de contexte : résumé pondéré des timesteps\n",
    "class Attention(Layer):\n",
    "    def __init__(self):\n",
    "        super(Attention, self).__init__()\n",
    "        self.dense = Dense(1)  # couche Dense qui calcule un score d’importance pour chaque timestep\n",
    "\n",
    "    def call(self, inputs, return_attention=False):\n",
    "        score = tf.nn.softmax(self.dense(inputs), axis=1)  # normalise les scores sur la dimension temporelle\n",
    "        context = tf.reduce_sum(score * inputs, axis=1)    # vecteur résumé pondéré\n",
    "        if return_attention:\n",
    "            return context, score\n",
    "        return context\n",
    "\n",
    "# --- Définition du modèle LSTM + Attention ---\n",
    "def create_model(n_timesteps, n_features):\n",
    "    inputs = Input(shape=(n_timesteps, n_features))\n",
    "    x = LSTM(64, return_sequences=True)(inputs)  # LSTM nécessaire pour combiner les timesteps\n",
    "    x = Dropout(0.2)(x)                          # régularisation pour réduire l'overfitting\n",
    "    att = Attention()(x)                          # attention sur tous les timesteps\n",
    "    x = Dense(32, activation=\"selu\")(att)        # dense pour combiner les informations (selu, tanh, gelu)\n",
    "    output = Dense(1, activation=\"sigmoid\")(x)   # sigmoid pour obtenir une probabilité entre 0 et 1\n",
    "    model = Model(inputs, output)\n",
    "    model.compile(optimizer=\"adam\", \n",
    "                  loss=\"binary_crossentropy\",  # perte adaptée pour classification binaire\n",
    "                  metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "# --- Liste de fenêtres temporelles à tester ---\n",
    "windows = [10, 20, 30, 50, 60]  \n",
    "results = {}\n",
    "\n",
    "for window in windows:\n",
    "    print(f\"\\n=== Fenêtre temporelle = {window} ===\")\n",
    "    X_seq, y_seq = create_sequences(X, y, window)\n",
    "    n_timesteps = X_seq.shape[1]\n",
    "    n_features = X_seq.shape[2]\n",
    "\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "    acc_list = []\n",
    "    roc_list = []\n",
    "    precision_list = []\n",
    "    recall_list = []\n",
    "    f1_list = []\n",
    "\n",
    "    for train_idx, test_idx in tscv.split(X_seq):\n",
    "        X_train, X_test = X_seq[train_idx], X_seq[test_idx]\n",
    "        y_train, y_test = y_seq[train_idx], y_seq[test_idx]\n",
    "\n",
    "        # --- Scaling sur le fold ---\n",
    "        scaler = StandardScaler()\n",
    "        X_train_2d = X_train.reshape(-1, n_features)\n",
    "        X_test_2d = X_test.reshape(-1, n_features)\n",
    "        X_train_scaled = scaler.fit_transform(X_train_2d).reshape(-1, n_timesteps, n_features)\n",
    "        X_test_scaled = scaler.transform(X_test_2d).reshape(-1, n_timesteps, n_features)\n",
    "\n",
    "        # --- Création et entraînement du modèle ---\n",
    "        model = create_model(n_timesteps, n_features)\n",
    "        model.fit(X_train_scaled, y_train, validation_data=(X_test_scaled, y_test),\n",
    "                  epochs=10, batch_size=32, verbose=0)\n",
    "\n",
    "        y_pred = (model.predict(X_test_scaled) > 0.5).astype(int)\n",
    "        acc_list.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "    results[window] = np.mean(acc_list)\n",
    "    print(f\"Accuracy moyenne: {results[window]:.4f}\")\n",
    "\n",
    "# --- Sélection de la fenêtre optimale - par rapport à l'accuracy ---\n",
    "print(\"\\nFenêtre optimale:\", max(results, key=results.get), \n",
    "      \"avec accuracy =\", max(results.values()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projet-deep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
